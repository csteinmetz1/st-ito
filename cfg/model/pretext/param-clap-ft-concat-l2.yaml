# pretrained and unfrozen (finetuning) CLAP model
model:
  class_path: lcap.methods.param.ParameterEstimator
  init_args:
    lr: 0.0001
    num_instances: 63
    num_presets: 10
    max_epochs: 250
    weight_decay: 0.0001
    embed_mode: concat
    norm: L2
    
    encoder:
      class_path: lcap.models.clap.CLAP
      init_args:
        pretrained: true
        frozen: false


